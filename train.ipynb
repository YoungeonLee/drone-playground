{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from utils import LABELS, preprocess_data\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(x, y, test_size=0.3):\n",
    "    # shuffle data\n",
    "    temp = list(zip(x, y))\n",
    "    random.shuffle(temp)\n",
    "    x, y = zip(*temp)\n",
    "    x, y = list(x), list(y)\n",
    "    \n",
    "    # split data\n",
    "    cutoff_index = int(len(x) * (1 - test_size))\n",
    "    x_train = x[:cutoff_index]\n",
    "    x_test = x[cutoff_index:]\n",
    "    y_train = y[:cutoff_index]\n",
    "    y_test = y[cutoff_index:]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data length: 3900\n",
      "Train data length: 2730\n",
      "Test data length: 1170\n"
     ]
    }
   ],
   "source": [
    "data_root = os.path.abspath('raw_data')\n",
    "all_paths = list(tf.io.gfile.glob(data_root + r'/*/*'))\n",
    "if not all_paths:\n",
    "    raise ValueError('Image dataset directory is empty.')\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for path in all_paths:\n",
    "    label = os.path.basename(os.path.dirname(path))\n",
    "    hand_data = pickle.load(open(path, 'rb'))\n",
    "    for frame in hand_data:\n",
    "        processed_data = preprocess_data(frame.hand)\n",
    "        x.append(processed_data)\n",
    "        y.append(LABELS[label])\n",
    "\n",
    "assert len(x) == len(y)\n",
    "print(f\"Total data length: {len(x)}\")\n",
    "\n",
    "_x_train, _y_train, _x_test, _y_test = split_train_test(x, y)\n",
    "print(f\"Train data length: {len(_x_train)}\")\n",
    "print(f\"Test data length: {len(_x_test)}\")\n",
    "\n",
    "x_train = np.array(_x_train)\n",
    "y_train = np.array(_y_train)\n",
    "x_test = np.array(_x_test)\n",
    "y_test = np.array(_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(21, 3)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(8)\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n",
      "86/86 [==============================] - 0s 509us/step - loss: 1.5130 - accuracy: 0.4619\n",
      "Epoch 2/28\n",
      "86/86 [==============================] - 0s 498us/step - loss: 0.8394 - accuracy: 0.8143\n",
      "Epoch 3/28\n",
      "86/86 [==============================] - 0s 494us/step - loss: 0.4901 - accuracy: 0.9227\n",
      "Epoch 4/28\n",
      "86/86 [==============================] - 0s 492us/step - loss: 0.3185 - accuracy: 0.9615\n",
      "Epoch 5/28\n",
      "86/86 [==============================] - 0s 498us/step - loss: 0.2092 - accuracy: 0.9802\n",
      "Epoch 6/28\n",
      "86/86 [==============================] - 0s 502us/step - loss: 0.1595 - accuracy: 0.9886\n",
      "Epoch 7/28\n",
      "86/86 [==============================] - 0s 497us/step - loss: 0.1195 - accuracy: 0.9927\n",
      "Epoch 8/28\n",
      "86/86 [==============================] - 0s 520us/step - loss: 0.0891 - accuracy: 0.9960\n",
      "Epoch 9/28\n",
      "86/86 [==============================] - 0s 529us/step - loss: 0.0701 - accuracy: 0.9985\n",
      "Epoch 10/28\n",
      "86/86 [==============================] - 0s 527us/step - loss: 0.0584 - accuracy: 0.9985\n",
      "Epoch 11/28\n",
      "86/86 [==============================] - 0s 516us/step - loss: 0.0494 - accuracy: 0.9989\n",
      "Epoch 12/28\n",
      "86/86 [==============================] - 0s 511us/step - loss: 0.0409 - accuracy: 0.9993\n",
      "Epoch 13/28\n",
      "86/86 [==============================] - 0s 529us/step - loss: 0.0356 - accuracy: 0.9989\n",
      "Epoch 14/28\n",
      "86/86 [==============================] - 0s 549us/step - loss: 0.0305 - accuracy: 0.9996\n",
      "Epoch 15/28\n",
      "86/86 [==============================] - 0s 578us/step - loss: 0.0257 - accuracy: 0.9989\n",
      "Epoch 16/28\n",
      "86/86 [==============================] - 0s 519us/step - loss: 0.0218 - accuracy: 0.9996\n",
      "Epoch 17/28\n",
      "86/86 [==============================] - 0s 492us/step - loss: 0.0202 - accuracy: 0.9996\n",
      "Epoch 18/28\n",
      "86/86 [==============================] - 0s 489us/step - loss: 0.0181 - accuracy: 0.9993\n",
      "Epoch 19/28\n",
      "86/86 [==============================] - 0s 498us/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 20/28\n",
      "86/86 [==============================] - 0s 491us/step - loss: 0.0140 - accuracy: 0.9996\n",
      "Epoch 21/28\n",
      "86/86 [==============================] - 0s 487us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 22/28\n",
      "86/86 [==============================] - 0s 485us/step - loss: 0.0119 - accuracy: 0.9996\n",
      "Epoch 23/28\n",
      "86/86 [==============================] - 0s 494us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 24/28\n",
      "86/86 [==============================] - 0s 503us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 25/28\n",
      "86/86 [==============================] - 0s 501us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 26/28\n",
      "86/86 [==============================] - 0s 497us/step - loss: 0.0088 - accuracy: 0.9996\n",
      "Epoch 27/28\n",
      "86/86 [==============================] - 0s 511us/step - loss: 0.0080 - accuracy: 0.9996\n",
      "Epoch 28/28\n",
      "86/86 [==============================] - 0s 494us/step - loss: 0.0068 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2940ab010>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=28, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 - 0s - loss: 0.0043 - accuracy: 1.0000 - 77ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004328994080424309, 1.0]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "probability_model.save('gesture_recognizer.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
